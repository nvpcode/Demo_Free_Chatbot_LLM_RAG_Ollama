import json
import os
import threading
import time
from typing import Dict, List, Tuple, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import numpy as np
from difflib import SequenceMatcher
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import hashlib
import pickle
from datetime import datetime, timedelta

class CacheEntry:
    """L·ªõp ƒë·∫°i di·ªán cho m·ªôt entry trong cache"""
    def __init__(self, question: str, answer: str, timestamp: datetime = None):
        self.question = question
        self.answer = answer
        self.timestamp = timestamp or datetime.now()
        self.access_count = 0
        self.last_accessed = timestamp or datetime.now()
    
    def update_access(self):
        """C·∫≠p nh·∫≠t th√¥ng tin truy c·∫≠p"""
        self.access_count += 1
        self.last_accessed = datetime.now()
    
    def to_dict(self):
        """Chuy·ªÉn ƒë·ªïi th√†nh dictionary ƒë·ªÉ l∆∞u tr·ªØ"""
        return {
            'question': self.question,
            'answer': self.answer,
            'timestamp': self.timestamp.isoformat(),
            'access_count': self.access_count,
            'last_accessed': self.last_accessed.isoformat()
        }
    
    @classmethod
    def from_dict(cls, data: dict):
        """T·∫°o instance t·ª´ dictionary"""
        entry = cls(
            question=data['question'],
            answer=data['answer'],
            timestamp=datetime.fromisoformat(data['timestamp'])
        )
        entry.access_count = data['access_count']
        entry.last_accessed = datetime.fromisoformat(data['last_accessed'])
        return entry

class TextSimilarityThread:
    """Lu·ªìng 1: So s√°nh t·ª´ ng·ªØ th√¥ng th∆∞·ªùng"""
    
    def __init__(self, similarity_threshold: float = 0.8):
        self.similarity_threshold = similarity_threshold
        self.vectorizer = TfidfVectorizer(
            stop_words='english',
            ngram_range=(1, 2),
            max_features=1000
        )
        self.question_vectors = None
        self.questions = []
    
    def update_questions(self, questions: List[str]):
        """C·∫≠p nh·∫≠t danh s√°ch c√¢u h·ªèi v√† t√≠nh to√°n vector"""
        if questions:
            self.questions = questions
            self.question_vectors = self.vectorizer.fit_transform(questions)
    
    def find_similar_question(self, query: str) -> Tuple[Optional[str], float]:
        """T√¨m c√¢u h·ªèi t∆∞∆°ng t·ª± s·ª≠ d·ª•ng TF-IDF v√† cosine similarity"""
        if not self.questions or self.question_vectors is None:
            return None, 0.0
        
        # T√≠nh vector cho c√¢u h·ªèi m·ªõi
        query_vector = self.vectorizer.transform([query])
        
        # T√≠nh cosine similarity
        similarities = cosine_similarity(query_vector, self.question_vectors).flatten()
        
        # T√¨m c√¢u h·ªèi c√≥ ƒë·ªô t∆∞∆°ng t·ª± cao nh·∫•t
        max_similarity_idx = np.argmax(similarities)
        max_similarity = similarities[max_similarity_idx]
        
        if max_similarity >= self.similarity_threshold:
            return self.questions[max_similarity_idx], max_similarity
        
        return None, max_similarity
    
    def find_similar_question_fuzzy(self, query: str) -> Tuple[Optional[str], float]:
        """T√¨m c√¢u h·ªèi t∆∞∆°ng t·ª± s·ª≠ d·ª•ng fuzzy matching"""
        if not self.questions:
            return None, 0.0
        
        best_match = None
        best_ratio = 0.0
        
        for question in self.questions:
            # S·ª≠ d·ª•ng SequenceMatcher ƒë·ªÉ so s√°nh
            ratio = SequenceMatcher(None, query.lower(), question.lower()).ratio()
            if ratio > best_ratio:
                best_ratio = ratio
                best_match = question
        
        if best_ratio >= self.similarity_threshold:
            return best_match, best_ratio
        
        return None, best_ratio

class VectorSimilarityThread:
    """Lu·ªìng 2: So s√°nh vector bi·ªÉu di·ªÖn"""
    
    def __init__(self, similarity_threshold: float = 0.85):
        self.similarity_threshold = similarity_threshold
        self.question_embeddings = {}
        self.embedding_model = None
    
    def set_embedding_model(self, embedding_model):
        """Thi·∫øt l·∫≠p model embedding"""
        self.embedding_model = embedding_model
    
    def update_question_embeddings(self, questions: List[str]):
        """C·∫≠p nh·∫≠t embedding cho danh s√°ch c√¢u h·ªèi"""
        if not self.embedding_model:
            return
        
        self.question_embeddings.clear()
        for question in questions:
            try:
                embedding = self.embedding_model.embed_query(question)
                self.question_embeddings[question] = embedding
            except Exception as e:
                print(f"L·ªói khi t·∫°o embedding cho c√¢u h·ªèi: {e}")
    
    def find_similar_question(self, query: str) -> Tuple[Optional[str], float]:
        """T√¨m c√¢u h·ªèi t∆∞∆°ng t·ª± s·ª≠ d·ª•ng vector similarity"""
        if not self.question_embeddings or not self.embedding_model:
            return None, 0.0
        
        try:
            # T·∫°o embedding cho c√¢u h·ªèi m·ªõi
            query_embedding = self.embedding_model.embed_query(query)
            
            best_match = None
            best_similarity = 0.0
            
            # So s√°nh v·ªõi t·∫•t c·∫£ c√¢u h·ªèi trong cache
            for question, embedding in self.question_embeddings.items():
                # T√≠nh cosine similarity
                similarity = self._cosine_similarity(query_embedding, embedding)
                
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = question
            
            if best_similarity >= self.similarity_threshold:
                return best_match, best_similarity
            
            return None, best_similarity
            
        except Exception as e:
            print(f"L·ªói khi t√¨m ki·∫øm vector similarity: {e}")
            return None, 0.0
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """T√≠nh cosine similarity gi·ªØa 2 vector"""
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)

class CacheManager:
    """Qu·∫£n l√Ω cache v·ªõi 2 lu·ªìng t√¨m ki·∫øm"""
    
    def __init__(self, 
                 cache_file: str = "cache_data.pkl",
                 max_cache_size: int = 1000,
                 cache_expiry_days: int = 30):
        self.cache_file = cache_file
        self.max_cache_size = max_cache_size
        self.cache_expiry_days = cache_expiry_days
        
        # Kh·ªüi t·∫°o 2 lu·ªìng
        self.text_thread = TextSimilarityThread()
        self.vector_thread = VectorSimilarityThread()
        
        # Cache storage
        self.cache: Dict[str, CacheEntry] = {}
        self.cache_lock = threading.Lock()
        
        # Load cache t·ª´ file
        self.load_cache()
        
        # Thread pool cho vi·ªác t√¨m ki·∫øm song song
        self.executor = ThreadPoolExecutor(max_workers=2)
    
    def set_embedding_model(self, embedding_model):
        """Thi·∫øt l·∫≠p model embedding cho vector thread"""
        self.vector_thread.set_embedding_model(embedding_model)
        self._update_thread_questions()
    
    def _update_thread_questions(self):
        """C·∫≠p nh·∫≠t danh s√°ch c√¢u h·ªèi cho c·∫£ 2 thread"""
        questions = list(self.cache.keys())
        self.text_thread.update_questions(questions)
        self.vector_thread.update_question_embeddings(questions)
    
    def add_to_cache(self, question: str, answer: str):
        """Th√™m c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi v√†o cache"""
        with self.cache_lock:
            # T·∫°o hash key cho c√¢u h·ªèi
            question_hash = hashlib.md5(question.lower().encode()).hexdigest()
            
            # Th√™m v√†o cache
            self.cache[question_hash] = CacheEntry(question, answer)
            
            # Ki·ªÉm tra k√≠ch th∆∞·ªõc cache
            if len(self.cache) > self.max_cache_size:
                self._cleanup_cache()
            
            # C·∫≠p nh·∫≠t questions cho c√°c thread
            self._update_thread_questions()
            
            # L∆∞u cache
            self.save_cache()
    
    def get_from_cache(self, question: str) -> Optional[str]:
        """L·∫•y c√¢u tr·∫£ l·ªùi t·ª´ cache n·∫øu c√≥ c√¢u h·ªèi t∆∞∆°ng t·ª±"""
        # T·∫°o hash cho c√¢u h·ªèi hi·ªán t·∫°i
        current_hash = hashlib.md5(question.lower().encode()).hexdigest()
        
        # Ki·ªÉm tra cache tr·ª±c ti·∫øp tr∆∞·ªõc
        if current_hash in self.cache:
            entry = self.cache[current_hash]
            entry.update_access()
            return entry.answer
        
        # S·ª≠ d·ª•ng 2 lu·ªìng ƒë·ªÉ t√¨m ki·∫øm song song
        futures = []
        
        # Lu·ªìng 1: Text similarity
        futures.append(
            self.executor.submit(self.text_thread.find_similar_question, question)
        )
        
        # Lu·ªìng 2: Vector similarity
        futures.append(
            self.executor.submit(self.vector_thread.find_similar_question, question)
        )
        
        # Ch·ªù k·∫øt qu·∫£ t·ª´ c·∫£ 2 lu·ªìng
        best_match = None
        best_similarity = 0.0
        best_method = ""
        
        for future in as_completed(futures):
            try:
                similar_question, similarity = future.result()
                if similar_question and similarity > best_similarity:
                    best_match = similar_question
                    best_similarity = similarity
                    best_method = "text" if future == futures[0] else "vector"
            except Exception as e:
                print(f"L·ªói khi t√¨m ki·∫øm cache: {e}")
        
        # N·∫øu t√¨m th·∫•y c√¢u h·ªèi t∆∞∆°ng t·ª±
        if best_match and best_similarity > 0.5:
            # T√¨m hash c·ªßa c√¢u h·ªèi t∆∞∆°ng t·ª±
            for q_hash, entry in self.cache.items():
                if entry.question == best_match:
                    entry.update_access()
                    print(f"ÔøΩ Cache hit! S·ª≠ d·ª•ng {best_method} similarity (ƒë·ªô t∆∞∆°ng t·ª±: {best_similarity:.3f})")
                    return entry.answer
        
        print(f"‚ùå Cache miss! Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi t∆∞∆°ng t·ª±")
        return None
    
    def _cleanup_cache(self):
        """D·ªçn d·∫πp cache: x√≥a c√°c entry c≈© v√† √≠t s·ª≠ d·ª•ng"""
        current_time = datetime.now()
        expiry_time = current_time - timedelta(days=self.cache_expiry_days)
        
        # L·ªçc c√°c entry h·∫øt h·∫°n
        expired_keys = [
            key for key, entry in self.cache.items()
            if entry.timestamp < expiry_time
        ]
        
        for key in expired_keys:
            del self.cache[key]
        
        # N·∫øu v·∫´n c√≤n qu√° nhi·ªÅu, x√≥a c√°c entry √≠t s·ª≠ d·ª•ng
        if len(self.cache) > self.max_cache_size:
            sorted_entries = sorted(
                self.cache.items(),
                key=lambda x: (x[1].access_count, x[1].last_accessed)
            )
            
            # X√≥a 20% entry √≠t s·ª≠ d·ª•ng nh·∫•t
            delete_count = int(len(self.cache) * 0.2)
            for i in range(delete_count):
                if i < len(sorted_entries):
                    del self.cache[sorted_entries[i][0]]
    
    def save_cache(self):
        """L∆∞u cache v√†o file"""
        try:
            cache_data = {
                key: entry.to_dict() 
                for key, entry in self.cache.items()
            }
            
            with open(self.cache_file, 'wb') as f:
                pickle.dump(cache_data, f)
                
        except Exception as e:
            print(f"L·ªói khi l∆∞u cache: {e}")
    
    def load_cache(self):
        """Load cache t·ª´ file"""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'rb') as f:
                    cache_data = pickle.load(f)
                
                self.cache = {
                    key: CacheEntry.from_dict(data)
                    for key, data in cache_data.items()
                }
                
                print(f"\n‚úÖ ƒê√£ load {len(self.cache)} entries t·ª´ cache")
                
        except Exception as e:
            print(f"L·ªói khi load cache: {e}")
            self.cache = {}
    
    def get_cache_stats(self) -> Dict:
        """L·∫•y th·ªëng k√™ v·ªÅ cache"""
        with self.cache_lock:
            total_entries = len(self.cache)
            total_access = sum(entry.access_count for entry in self.cache.values())
            
            if total_entries > 0:
                avg_access = total_access / total_entries
            else:
                avg_access = 0
            
            return {
                'total_entries': total_entries,
                'total_access': total_access,
                'average_access': avg_access,
                'cache_size_mb': os.path.getsize(self.cache_file) / (1024 * 1024) if os.path.exists(self.cache_file) else 0
            }
    
    def clear_cache(self):
        """X√≥a to√†n b·ªô cache"""
        with self.cache_lock:
            self.cache.clear()
            if os.path.exists(self.cache_file):
                os.remove(self.cache_file)
            print("üóëÔ∏è ƒê√£ x√≥a to√†n b·ªô cache")


# V√≠ d·ª• s·ª≠ d·ª•ng
if __name__ == "__main__":
    # Kh·ªüi t·∫°o cache manager
    cache_manager = CacheManager()
    
    # Test th√™m m·ªôt s·ªë c√¢u h·ªèi
    test_qa = [
        ("B·∫°n c√≥ th·ªÉ gi·∫£i th√≠ch v·ªÅ machine learning kh√¥ng?", "Machine learning l√† m·ªôt nh√°nh c·ªßa AI..."),
        ("ML l√† g√¨?", "ML vi·∫øt t·∫Øt c·ªßa Machine Learning..."),
        ("L√†m th·∫ø n√†o ƒë·ªÉ h·ªçc deep learning?", "ƒê·ªÉ h·ªçc deep learning, b·∫°n c·∫ßn...")
    ]
    
    for question, answer in test_qa:
        cache_manager.add_to_cache(question, answer)
    
    # Test t√¨m ki·∫øm
    test_question = "Machine learning l√† g√¨?"
    result = cache_manager.get_from_cache(test_question)
    
    if result:
        print(f"T√¨m th·∫•y c√¢u tr·∫£ l·ªùi: {result}")
    else:
        print("Kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi t∆∞∆°ng t·ª±")
    
    # In th·ªëng k√™
    stats = cache_manager.get_cache_stats()
    print(f"Th·ªëng k√™ cache: {stats}")